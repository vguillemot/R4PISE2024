[
  {
    "objectID": "pages/D_MFA.html",
    "href": "pages/D_MFA.html",
    "title": "Multiple Factor Analysis on Wines",
    "section": "",
    "text": "We will need the following libraries for this example, if these are not installed install them with remotes or pak\n\n\nR code\n# de-comment the following lines to\n# install missing packages\n#install.packages(\"pak\")\n# pak::pak('dplyr')\nlibrary(dplyr)\n#&gt; \n#&gt; Attaching package: 'dplyr'\n#&gt; The following objects are masked from 'package:stats':\n#&gt; \n#&gt;     filter, lag\n#&gt; The following objects are masked from 'package:base':\n#&gt; \n#&gt;     intersect, setdiff, setequal, union\nlibrary(knitr)\nlibrary(kableExtra)\n#&gt; \n#&gt; Attaching package: 'kableExtra'\n#&gt; The following object is masked from 'package:dplyr':\n#&gt; \n#&gt;     group_rows\nlibrary(ggplot2)\nlibrary(TExPosition)\n#&gt; Loading required package: prettyGraphs\n#&gt; Loading required package: ExPosition\n#pak::pak('HerveAbdi/data4PCCAR')\nlibrary(data4PCCAR)\n#pak::pak('HerveAbdi/PTCA4CATA')\nlibrary(FactoMineR)\nsuppressMessages(library(factoextra))\n#pak::pak('gastonstat/colortools')\nlibrary(colortools)\nlibrary(coin)\n#&gt; Loading required package: survival\n# suppressMessages(library(XLConnect))\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(FactoMineR)\nlibrary(factoextra)"
  },
  {
    "objectID": "pages/D_MFA.html#where-are-the-results-you-need",
    "href": "pages/D_MFA.html#where-are-the-results-you-need",
    "title": "Multiple Factor Analysis on Wines",
    "section": "Where are the results you need:",
    "text": "Where are the results you need:\nThe list resMFA contains all the informtion needed to interpret the results of the analysis.\n\nThe \\(\\mathbf{R_v}\\) coefficient matrix\n\n\nR code\n# a nice heatmap\n\nresMFA$group$RV %&gt;%\n  as_tibble(rownames = \"rows\") %&gt;%\n  pivot_longer(-1, names_to = \"cols\") %&gt;%\n    mutate(cols = factor(cols, levels = rev(unique(cols)))) %&gt;%\n  ggplot(aes(x = rows, y = cols)) +\n  geom_tile(aes(fill = value)) +  \n  geom_text(aes(label = round(value, 2)), color = \"white\", fontface = \"bold\") +  \n  scale_fill_gradient2(low = \"#BB4444\", mid =  \"#FFFFFF\", high = \"#4477AA\", midpoint = 0, limits = c(-1, 1 + 1e-10)) +\n  coord_equal() + \n  scale_x_discrete(position = \"top\") +\n  labs(x = \"\", y = \"\", fill) +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nR code\n\n# col &lt;- colorRampPalette(\n#   c(\"#BB4444\", \"#EE9988\", \"#FFFFFF\", \"#77AADD\", \"#4477AA\")\n#   )\n# plot.RV &lt;- corrplot::corrplot(resMFA$group$RV, \n#                            method = \"color\",\n#                            col = col(201), \n#                            addCoef.col = \"black\", \n#                            number.cex = 0.8, \n#                            tl.col = \"black\", \n#                            mar = c(0,0,0,0),\n#                            addgrid.col = \"grey\", \n#                            tl.srt = 90)\n# print(plot.RV)\n\n\nA first step is to look at the \\(R_V\\) matrix—A matrix that stores the values of the \\(R_v\\) coefficient between pairs of the original data tables (adn also with the whole MFA).\nFor MFA, these coefficients are only descriptive and can be interpreted like a squared coefficient of correlation for matrices: a value close to 1 for a pair of data tables indicates that these two tables are storing similar information, a value close to zero indicates that these tables store independent information.\n\n\nWeights (alpha in the paper) applied to each data table\nYou can show the alphas with a barplot\n\n\nR code\n#Eig.tab &lt;- demo.mfa.2007$mexPosition.Data$Compromise$compromise.eigs\nEig.tab &lt;- c(resMFA$separate.analyses$E1$eig[1],\n             resMFA$separate.analyses$E1$eig[2],\n             resMFA$separate.analyses$E1$eig[3])\nAlpha &lt;- 1/sqrt(Eig.tab)\n\n\n\n\n\nMain results:\n\n\nR code\n#Eig4scree &lt;- demo.mfa.2007$mexPosition.Data$Table$eigs\nEig4scree &lt;- resMFA$global.pca$eig[,1]\nTau4scree &lt;- resMFA$global.pca$eig[,2]\n# Use factorextra\n# Eigenvalues/variances of dimensions\nfviz_screeplot(resMFA)\n\n\n\n\n\n\n\n\n\n\nGlobal factor scores of the rows:\nThis shows how the rows are projected onto the space from the point of all tables\n(You want to plot them like how you plot them in PCA: Component 1 vs. Component 2)\n\n\nR code\nfi &lt;- resMFA$global.pca$ind$coord\nfviz_mfa_ind(resMFA, col.ind = \"cos2\",\n  gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n  repel = TRUE)\n\n\n\n\n\n\n\n\n\n\n\nPartial factor scores of the rows: how the rows are viewed from the persepctive of each table\n(You want to plot them with the global factor scores. Please check out the example of DiSTATIS to see how you plot them.)\n\n\nR code\n# Partial individuals\nfviz_mfa_ind(resMFA, partial = \"all\")\n\n\n\n\n\n\n\n\n\n\n\nLoadings of variables\n(You interpret them as in PCA.)\n\n\nR code\n# Quantitative variables\nfviz_mfa_var(resMFA, \"quanti.var\", palette = \"jco\", \n             repel = TRUE)\n\n\n\n\n\n\n\n\n\n\n\nContributions\nLeft as an exercise."
  },
  {
    "objectID": "pages/C_PLSC.html",
    "href": "pages/C_PLSC.html",
    "title": "PLSC on Wines",
    "section": "",
    "text": "R code\nlibrary(R4SPISE2022)"
  },
  {
    "objectID": "pages/C_PLSC.html#load-the-course-library",
    "href": "pages/C_PLSC.html#load-the-course-library",
    "title": "PLSC on Wines",
    "section": "",
    "text": "R code\nlibrary(R4SPISE2022)"
  },
  {
    "objectID": "pages/C_PLSC.html#load-the-data",
    "href": "pages/C_PLSC.html#load-the-data",
    "title": "PLSC on Wines",
    "section": "Load the data",
    "text": "Load the data\nWith the following command\n\n\nR code\ndata(\"winesOf3Colors\", package = \"data4PCCAR\")\n\n\n\n\nR code\nwineColors &lt;- list()\nwineColors$oc &lt;- as.matrix(as.character(recode(winesOf3Colors$winesDescriptors$color, red = 'indianred4', \n                white = 'gold', rose = 'lightpink2')))\nwineColors$gc &lt;- as.matrix(c(red = 'indianred4', \n                white = 'gold', rose = 'lightpink2'))\n\nvarColors &lt;- list()\nvarColors$oc[[1]] &lt;- as.matrix(rep(\"darkorange1\", 4))\nvarColors$oc[[2]] &lt;- as.matrix(rep(\"olivedrab3\", 8))\n    \n\n\nMore information on the dataset is available on the corresponding vignette: vignette(\"A3_DataWines\")."
  },
  {
    "objectID": "pages/C_PLSC.html#two-tables-with-descriptors-and-other-supplementary-information",
    "href": "pages/C_PLSC.html#two-tables-with-descriptors-and-other-supplementary-information",
    "title": "PLSC on Wines",
    "section": "Two tables with descriptors and other supplementary information",
    "text": "Two tables with descriptors and other supplementary information\n\n\nR code\ndescr &lt;- winesOf3Colors$winesDescriptors %&gt;% \n    select(origin, color, varietal)\nsuppl &lt;- winesOf3Colors$winesDescriptors %&gt;% \n    select(Price)\nchemi &lt;- winesOf3Colors$winesDescriptors %&gt;% \n    select(Acidity, Alcohol, Sugar, Tannin)\nsenso &lt;- winesOf3Colors$winesDescriptors %&gt;% \n    select(fruity, floral, vegetal, \n           spicy, woody, sweet, astringent, \n           hedonic)\n\n\n\nTwo data tables\n\nFirst table: chemical data (chemi) that includes acidity, alcohol, sugar, and tannin.\nSecond table: sensory data (senso) that includes fruity, floral, vegetal, spicy, woody, sweet, astringent, and hedonic.\n\n\n\nDescriptors and supplementary variable\n\nDescriptors: origin, color and varietal.\nSupplementary variables: Price."
  },
  {
    "objectID": "pages/C_PLSC.html#run-partial-least-square-correlation-pls-c-on-the-two-tables",
    "href": "pages/C_PLSC.html#run-partial-least-square-correlation-pls-c-on-the-two-tables",
    "title": "PLSC on Wines",
    "section": "Run Partial Least Square Correlation (PLS-C) on the two tables",
    "text": "Run Partial Least Square Correlation (PLS-C) on the two tables\n\n\nR code\nres.pls &lt;- tepPLS(chemi, senso, DESIGN = descr$color, graphs = FALSE)\n\n\nThe default of this function will center (to have means equal 0) and scale (to have the sums of squares equal 1) all variables in both data tables. The argument DESIGN indicates the groups of the observations and change how the observations are colored in the figures (when graphs = TRUE), but it does not change the results of PLS-C."
  },
  {
    "objectID": "pages/C_PLSC.html#generate-the-figures",
    "href": "pages/C_PLSC.html#generate-the-figures",
    "title": "PLSC on Wines",
    "section": "Generate the figures",
    "text": "Generate the figures\n\n\nR code\n## You might need to load these packages if the error is saying that it couldn't find some functions\n\nres.pls.plot &lt;- TTAplot(\n    res = res.pls, # Output of tepPLS\n    color.obs = wineColors, # &lt;optional&gt; colors of wines\n    color.tab = varColors, # &lt;optional&gt; colors of the two tables\n    tab1.name = \"Chemical data\", # &lt;optional&gt; Name of Table 1 (for printing)\n    tab2.name = \"Sensory data\", # &lt;optional&gt; Name of Table 2 (for printing)\n    DESIGN = descr$color, # design for the wines\n    tab1 = chemi,  # First data table\n    tab2 = senso)  # Second data table\n\n\nIn this TTAplot function, if DESIGN is specified. The latent variables will be colored according to the groups of the observations with the group means and their 95% bootstrap confidence intervals.\n\nCorrelation between the two tables\nWe can check the data by plotting first the correlation matrix between the two data sets. This correlation matrix is where the dimensions are extracted.\n\n\nR code\nres.pls.plot$results.graphs$heatmap.rxy\n\n\n\n\n\n\n\n\n\n\n\nScree plot\nThe scree plot shows the eigenvalues of each dimension. These eigenvalues give the squared covariance of each pair of latent variables. In other words, the singular values, which are the square root of the eigenvalues, give the covariance of these pairs of latent variables. The sum of the eigenvalues is equal to the sum of the squared covariance between all variables in both tables.\n\n\nR code\nres.pls.plot$results.graphs$scree.eig\n\n\n\n\n\n\n\n\n\n\n\nLatent variables\nHere, we plot the first latent variable of both tables against each other with the observations colored according to their groups. This plot shows how the observations are distributed on the dimension and how the chosen pair of latent variables are related to each other. When plotting the first pair of latent variables, we expect the observations to distribute along the bottom-left-to-top-right diagonal line (which illustrates a perfect association), because PLS-C maximizes the covariance of the latent variables.\nTo examine the stability of these groups, we plot the group means with their 95% bootstrap confidence intervals (or ellipsoids). If the ellipses do not overlap, the groups are reliably different from each other. However, it’s worth noted that the distribution of the observations does not imply how the groups (represented by the group means) are distributed or whether the groups are reliably different from each other.\nNote: The grouping information are independent from PLS-C and are only use to help provide a summary description of the observations.\n\n\nR code\nres.pls.plot$results.graphs$lv.plot\n\n\n\n\n\n\n\n\n\nThe results from Dimension 1 show that the association between the chemical and the sensory data reliably separates the red wines from rose and white wines.\n\n\nContributions\nThese bar plots illustrate the signed contribution of variables from the two data tables. From these figures, we use the direction and the magnitude of these signed contributions to interpret the dimension.\nThe direction of the signed contribution is the direction of the loadings, and it shows how the variables contribute to the dimension. The variables that contribute in a similar way have the same sign, and those that contribute in an opposite way will have different signs.\nThe magnitude of the contributions are computed as squared loadings, and they quantify the amount of variance contributed by each variable. Therefore, contribution is similar to the idea of an effect size. To identify the important variables, we find the variables that contribute more than average (i.e., with a big enough effect size). When the variables are centered and scaled to have their sums of squares equals 1, each variable contributes one unit of variance; therefore, the average contribution is 1/(# of variables of the table).\n\n\nR code\nres.pls.plot$results.graphs$ctrX.plot\n\n\n\n\n\n\n\n\n\nR code\nres.pls.plot$results.graphs$ctrY.plot\n\n\n\n\n\n\n\n\n\nFrom these two bar plots, the first dimension is characterized by (1) the positive association between Alcohol and Tannin from the Chemical data and Woody and Astringent from the Sensory data, and (2) the negative association between these variables and Hedonic from the Sensory data.\nTogether with the latent variable plot, we found that, as compared to the rose and the white wines in the sample, the red wines are less Hedonic and stronger in Alcohol, Tannin, Woody, and Astringent.\n\n\nCircles of correlations\nThe circle of correlations illustrate how the variables are correlated with each other and with the dimensions. From this figure, the length of an arrow indicates how much this variable is explained by the two given dimensions. The cosine between any two arrows gives their correlation. The cosine between a variable and an axis gives the correlation between that variable and the corresponding dimension.\nIn this figure, an angle closer to 0° indicates a correlation close to 1; an angle closer to 180° indicates a correlation close to -1; and an 90° angle indicates 0 correlation. However, it’s worth noted that this implication of correlation might only be true within the given dimensions. When a variable is far away from the circle, it is not fully explained by the dimensions, and other dimensions might be characterized by other pattern of relationship between this and other variables.\n\n\nR code\nres.pls.plot$results.graphs$cirCorX.plot\n\n\n\n\n\n\n\n\n\nR code\nres.pls.plot$results.graphs$cirCorY.plot\n\n\n\n\n\n\n\n\n\nThese circles of correlations show that Alcohol, Tannin, Woody, Astringent, and Hedonic are strongly correlated to Dimension 1 with Henodic inversely correlated with all other variables. These variables are mostly explained by the first dimension and have close-to-zero correlation with the second dimension (which is not included and discussed in the previous sections)."
  },
  {
    "objectID": "pages/C_PLSC.html#inference-plots-and-results",
    "href": "pages/C_PLSC.html#inference-plots-and-results",
    "title": "PLSC on Wines",
    "section": "Inference plots and results",
    "text": "Inference plots and results\nThe inference analysis of PCA (performed by OTAplotInference) includes bootstrap test of the proportion of variance explained, permutation tests of the eigenvalues, the bootstrap tests of the loadings (i.e., the left and the right singular vectors).\n\n\nR code\nres.plot.plsc.inference &lt;- TTAplotInference(\n    res = res.pls,\n    tab1 = chemi, \n    tab2 = senso, \n    DESIGN = descr$color,\n    tab1.name = \"Chemical data\", # &lt;optional&gt; Name of Table 1 (for printing)\n    tab2.name = \"Sensory data\" # &lt;optional&gt; Name of Table 2 (for printing)    \n    )\n\n\n\nBootstrap and permutation tests on the eigenvalues\nThe inference scree plot illustrates the 95% bootstrap confidence intervals of the eigenvalues. If an interval includes 0, the eigenvalue is reliably larger than 0.\n\n\nR code\nres.plot.plsc.inference$results.graphs$scree\n\n\n\n\n\n\n\n\n\nThe bootstrap test identifies two significant dimensions having eigenvalues reliably larger than 0. The permutation test identifies two significant dimensions with eigenvalues significantly larger than 0.\n\n\nBootstrap test on the loadings\nThe bar plot illustrates the bootstrap ratios which equals \\[\\frac{M_{p_{j}boot}}{SD_{p_{j}boot}},\\] where \\(M_{p_{j}boot}\\) is the mean of the bootstrapped sample of the jth loading and \\(SD_{p_{j}boot}\\) is the bootstrapped standard deviation of the factor score. A bootstrap ratio is equivalent to a t-statistics for the column factor score with the \\(\\mathrm{H}_0: g_j = 0\\). The threshold is set to 2 to approximate the critical t-value of 1.96 at \\(\\alpha\\) = .05.\n\n\nR code\nres.plot.plsc.inference$results.graphs$BR.X\n\n\n\n\n\n\n\n\n\nThe bootstrap test identifies Alcohol, Sugar, and Tannin as chemical variables with loadings significantly different from 0.\n\n\nR code\nres.plot.plsc.inference$results.graphs$BR.Y\n\n\n\n\n\n\n\n\n\nThe bootstrap test identifies Floral, Spicy, Woody, Sweet, Astringent and Hedonic as significant sensory variables with loadings different from 0.\nIt’s worth noted that the bootstrap ratio gives different information as contributions. Contributions describe the size of the effect, and the bootstrap ratios describe the reliability of the loadings. Therefore, when we interpret the results, we will combine both to draw a conclusion.\n\nInterpreting loadings with contributions and bootstrap ratios\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe results from the Chemical data show that Alcohol, Sugar, and Tannin all have loadings stably (or significantly) different from 0. But, only Alcohol and Tannin contribute a significant amount of variance to this dimension. Although the loading of Sugar is stable and is significant different from 0, the effect size is small; in other words, it’s not considered as important.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimilarly, for the Sensory data, the results show that Floral, Spicy, Woody, Sweet, Astringent and Hedonic all have loadings stably (or significantly) different from 0. But, only Woody, Astringent, and Hedoniccontribute a significant amount of variance to this dimension. In other words, the loadings of Floral, Spicy, Woody, Sweet, Astringent and Hedonic are stable and reliably different from 0, but the important variables that define this dimension are Woody, Astringent, and Hedonic."
  },
  {
    "objectID": "pages/A_Data.html",
    "href": "pages/A_Data.html",
    "title": "A Sensory Data Set on Wines of The World",
    "section": "",
    "text": "R code\n# Before loading the data, load the following packages\nlibrary(dplyr)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(ggplot2)\n\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD\nTo load the data, use the following command\nR code\n# Load the data with the following commands\n# &gt;&gt;&gt;&gt;&gt;&gt;&gt; 777cc1f2b89aa51d4ed2c66b13fffc418a1dbf37\ndata(\"winesOf3Colors\", package = \"data4PCCAR\")\nwineColors &lt;- winesOf3Colors$winesDescriptors$color\nwineColors &lt;- as.character(recode(wineColors, red = 'indianred4', \n                white = 'gold', rose = 'lightpink2'))"
  },
  {
    "objectID": "pages/A_Data.html#four-tables",
    "href": "pages/A_Data.html#four-tables",
    "title": "A Sensory Data Set on Wines of The World",
    "section": "Four tables",
    "text": "Four tables\nThere are four types of variables in the data:\n\nDescriptors: origin, color and varietal;\nSupplementary variables: Price;\nChemical data: Acidity, Alcohol, Sugar, and Tannin;\nSensory data: fruity, floral, vegetal, spicy, woody, sweet, astringent, and hedonic."
  },
  {
    "objectID": "pages/A_Data.html#the-sensory-scores",
    "href": "pages/A_Data.html#the-sensory-scores",
    "title": "A Sensory Data Set on Wines of The World",
    "section": "The sensory scores",
    "text": "The sensory scores"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R4SPISE2024",
    "section": "",
    "text": "Here, you will find data, programs, and documentation for the SPISE2024 Workshop A multi-dimensional approach using MCA, MFA, and PLS with R (from July 24 to July 25, Ho Chi Minh City)."
  },
  {
    "objectID": "index.html#reproducible-examples-in-r",
    "href": "index.html#reproducible-examples-in-r",
    "title": "R4SPISE2024",
    "section": "Reproducible examples in R",
    "text": "Reproducible examples in R\nStudents who are proficient in R are invited to check our reproducible examples out: all the data and code is available on this companion website.\nAll the necessary code to generate the figures and tables “hidden” in collapsed chunks of codes, like this one below.\nClick on the arrow to see the R code.\n\n\nR code\n# This is a comment!\n# And this, below, is a line of R code.\n# Copy and paste it in your own R console\n# to compute the median of three numbers: \n# -1, 0, and 1\nmedian(-1:1)\n# (the result will and should not surprise you)\n\n\n\nInstall our companion package\nWe made the data, as well as cool functions to plot your results, available in an R package that you can dowload and install with pak.\n\n## If needed, install pak first\ninstall.packages(\"pak\")\n## Install R4SPISE2022\npak::pak(\"HerveAbdi/R4SPISE2022\")\n\nThe ouput that you will get will depend on what is already installed on your computer, but should look like this:\n→ Will install 1 package.\n→ Will download 1 package with unknown size.\n+ R4SPISE2022   0.0.0.9000 👷🏿️🔧 ⬇ (GitHub: --------)\nℹ Getting 1 pkg with unknown size\n✔ Got R4SPISE2022 0.0.0.9000 (source) (7.85 MB)             \n✔ Downloaded 1 package (7.85 MB) in 21.8s                   \nℹ Packaging R4SPISE2022 0.0.0.9000\n✔ Packaged R4SPISE2022 0.0.0.9000 (7.4s)                    \nℹ Building R4SPISE2022 0.0.0.9000 \n✔ Built R4SPISE2022 0.0.0.9000 (2.8s) \n\n\nTest\nTo test the installation, run the following chunk of code that will show the help file of function OTAplot.\n\n\nR code\nlibrary(R4SPISE2022)\n\n\nRegistered S3 method overwritten by 'data4PCCAR':\n  method                  from     \n  print.str_colorsOfMusic PTCA4CATA\n\n\nR code\n?OTAplot"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About us",
    "section": "",
    "text": "I am a post-doctoral research fellow at Centre for Addiction and Mental Health (CAMH). My work focuses on developing advanced multivariate methods to integrate and examine the relationships between structural and functional brain connectivity. Prior to joining CAMH, I received my Ph.D. in Cognition & Neuroscience from the University of Texas at Dallas, where I focused on developing advanced multivariate methods (with sparsification and for novel applications) to analyze neuroscience data (including behavioral data, genetics data, fMRI data, and resting-state fMRI data)."
  },
  {
    "objectID": "about.html#ju-chi-yu",
    "href": "about.html#ju-chi-yu",
    "title": "About us",
    "section": "",
    "text": "I am a post-doctoral research fellow at Centre for Addiction and Mental Health (CAMH). My work focuses on developing advanced multivariate methods to integrate and examine the relationships between structural and functional brain connectivity. Prior to joining CAMH, I received my Ph.D. in Cognition & Neuroscience from the University of Texas at Dallas, where I focused on developing advanced multivariate methods (with sparsification and for novel applications) to analyze neuroscience data (including behavioral data, genetics data, fMRI data, and resting-state fMRI data)."
  },
  {
    "objectID": "about.html#hervé-abdi",
    "href": "about.html#hervé-abdi",
    "title": "About us",
    "section": "Hervé Abdi",
    "text": "Hervé Abdi\n\n\n\n\n\n\n\n\n\nI am a Professor at the University of Texas at Dallas in the School of Behavioral and Brain Sciences. My recent work focuses on face and person perception, odor perception, and computational modeling of these processes. I have developed statistical techniques to analyze large data sets, such as those found in genomics, brain imaging, and sensory evaluation, including principal component analysis and multiple factor analysis."
  },
  {
    "objectID": "about.html#vincent-guillemot",
    "href": "about.html#vincent-guillemot",
    "title": "About us",
    "section": "Vincent Guillemot",
    "text": "Vincent Guillemot\n\n\n\n\n\n\nI am currently a biostatistician in the Hub of Bioinformatics and Biostatistics. Before that, I worked at the Brain and Spine Institute (Paris, France), NeuroSpin (Saclay, France) and in the Ludwig Maximilian University (Munich, Germany). My fields of expertise include biostatistics, multivariate statistics, data visualization, statistical data integration and machine learning. My teaching activities range from the introduction to basic concepts in statistics to theoretical aspects in convex optimization."
  },
  {
    "objectID": "pages/E_PLSR.html",
    "href": "pages/E_PLSR.html",
    "title": "PLSR on Wines",
    "section": "",
    "text": "R code\nlibrary(R4SPISE2022)"
  },
  {
    "objectID": "pages/E_PLSR.html#load-the-course-library",
    "href": "pages/E_PLSR.html#load-the-course-library",
    "title": "PLSR on Wines",
    "section": "",
    "text": "R code\nlibrary(R4SPISE2022)"
  },
  {
    "objectID": "pages/E_PLSR.html#load-the-data",
    "href": "pages/E_PLSR.html#load-the-data",
    "title": "PLSR on Wines",
    "section": "Load the data",
    "text": "Load the data\nWith the following command\n\n\nR code\ndata(\"winesOf3Colors\", package = \"data4PCCAR\")\n\n\nMore information on the dataset is available on the corresponding vignette: vignette(\"A3_DataWines\")."
  },
  {
    "objectID": "pages/E_PLSR.html#two-tables-with-descriptors-and-other-supplementary-information",
    "href": "pages/E_PLSR.html#two-tables-with-descriptors-and-other-supplementary-information",
    "title": "PLSR on Wines",
    "section": "Two tables with descriptors and other supplementary information",
    "text": "Two tables with descriptors and other supplementary information\n\n\nR code\ndescr &lt;- winesOf3Colors$winesDescriptors %&gt;% \n    select(origin, color, varietal)\nsuppl &lt;- winesOf3Colors$winesDescriptors %&gt;% \n    select(Price)\nchemi &lt;- winesOf3Colors$winesDescriptors %&gt;% \n    select(Acidity, Alcohol, Sugar, Tannin)\nsenso &lt;- winesOf3Colors$winesDescriptors %&gt;% \n    select(fruity, floral, vegetal, \n           spicy, woody, sweet, astringent)\nchemisenso &lt;- winesOf3Colors$winesDescriptors %&gt;% \n    select(Acidity, Alcohol, Sugar, Tannin, fruity, floral, vegetal,\n           spicy, woody, sweet, astringent)\nhedo &lt;- winesOf3Colors$winesDescriptors %&gt;% \n    select(hedonic)\n\n\n\nPLS-R: Predicting one variable with a data table\n\nThe predictors (X): chemical data (chemi) that includes acidity, alcohol, sugar, and tannin.\nThe predicted (Y): hedonic (hedo).\n\n\n\nDescriptors and supplementary variable\n\nDescriptors: origin, color and varietal.\nSupplementary variables: Price."
  },
  {
    "objectID": "pages/E_PLSR.html#run-partial-least-square-regression-pls-r-on-the-two-tables",
    "href": "pages/E_PLSR.html#run-partial-least-square-regression-pls-r-on-the-two-tables",
    "title": "PLSR on Wines",
    "section": "Run Partial Least Square Regression (PLS-R) on the two tables",
    "text": "Run Partial Least Square Regression (PLS-R) on the two tables\nThe data4PCCAR::PLSR_SVD function takes two entries of data tables. The first entry will be the predictor table (X) and the second entry will be the predicted table (Y) as in a regression equation: \\(\\mathbf{Y = \\beta X + E}\\). In RA, the dimensions maximize \\(\\beta\\) of each pair of latent variables.\n\n\nR code\nres.plsr &lt;- data4PCCAR::PLSR_SVD(chemi, hedo, 3, inference = TRUE, displayJack = TRUE)\n\n\nThe function will center (to have means equal 0) and scale (to have the standard deviation equal 1) all variables in both data tables."
  },
  {
    "objectID": "pages/E_PLSR.html#generate-the-figures",
    "href": "pages/E_PLSR.html#generate-the-figures",
    "title": "PLSR on Wines",
    "section": "Generate the figures",
    "text": "Generate the figures\n\n\nR code\n## You might need to load these packages if the error is saying that it couldn't find some functions\n# library(PTCA4CATA) \n# library(data4PCCAR)\nres.plsr.plot &lt;- PLSRplot(\n    res = res.plsr, # Output of tepPLS\n    displayJack = TRUE,\n    color.obs = wineColors, # &lt;optional&gt; colors of wines\n    color.tab = varColors, # &lt;optional&gt; colors of the two tables\n    tab1.name = \"Chemical data\", # &lt;optional&gt; Name of Table 1 (for printing)\n    tab2.name = \"Hedonic\", # &lt;optional&gt; Name of Table 2 (for printing)\n    DESIGN = descr$color, # design for the wines\n    tab1 = chemi,  # First data table\n    tab2 = hedo)  # Second data table\n\n\nIn this PLSRplot function, if DESIGN is specified. The latent variables will be colored according to the groups of the observations with the group means and their 95% bootstrap confidence intervals.\n\nCorrelation between the two tables\nWe can check the data by plotting first the correlation matrix between the two data sets. This correlation matrix is where the dimensions are extracted.\n\n\nR code\nres.plsr.plot$results.graphs$heatmap.rxy\n\n\n\n\n\n\n\n\n\n\n\nScree plot\nThe scree plot shows the eigenvalues of each dimension. These eigenvalues give the squared coefficient of regression (\\(\\beta^2\\) = NA) of each pair of latent variables. In other words, the singular values, which are the square root of the eigenvalues, give the coefficient of regression (\\(\\beta\\) = NA) of these pairs of latent variables. The sum of the eigenvalues is equal to the sum of the squared correlation between all variables in both tables.\n\n\nR code\nres.plsr.plot$results.graphs$scree.eig.R2X\n\n\n\n\n\n\n\n\n\nR code\nres.plsr.plot$results.graphs$scree.eig.R2Y\n\n\n\n\n\n\n\n\n\nR code\nres.plsr.plot$results.graphs$scree.sv.R2X\n#&gt; NULL\nres.plsr.plot$results.graphs$scree.sv.R2Y\n#&gt; NULL\nres.plsr.plot$results.graphs$Y.RESS.plot\n\n\n\n\n\n\n\n\n\n\n\nThe prediction (fixed effect)\n\n\nR code\nres.plsr.plot$results.graphs$YYhat.plot\n\n\n\n\n\n\n\n\n\n\n\nLatent variables\nHere, we plot the first latent variable of both tables against each other with the observations colored according to their groups. This plot shows how the observations are distributed on the dimension and how the chosen pair of latent variables are related to each other. When plotting the first pair of latent variables, we expect the observations to distribute along the bottom-left-to-top-right diagonal line (which illustrates a perfect association), because RA maximizes the coefficient of regression of the latent variables.\nTo examine the stability of these groups, we plot the group means with their 95% bootstrap confidence intervals (or ellipsoids). If the ellipses do not overlap, the groups are reliably different from each other. However, it’s worth noted that the distribution of the observations does not imply how the groups (represented by the group means) are distributed or whether the groups are reliably different from each other.\nNote: The grouping information are independent from RA and are only use to help provide a summary description of the observations.\n\n\nR code\nres.plsr.plot$results.graphs$lv.plot\n\n\n\n\n\n\n\n\n\nThe results from Dimension 1 show that the chemical data can predict the performance of the sensory data, and such prediction separates the red wines from the rosé and the white wines, but not the rosé and the white.\n\n\nContributions\nThese bar plots illustrate the signed contribution of variables from the two data tables. From these figures, we use the direction and the magnitude of these signed contributions to interpret the dimension.\nThe direction of the signed contribution is the direction of the loadings, and it shows how the variables contribute to the dimension. The variables that contribute in a similar way have the same sign, and those that contribute in an opposite way will have different signs.\nThe magnitude of the contributions are computed as squared loadings, and they quantify the amount of variance contributed by each variable. Therefore, contribution is similar to the idea of an effect size. To identify the important variables, we find the variables that contribute more than average (i.e., with a big enough effect size). When the variables are centered and scaled to have their sums of squares equals 1, each variable contributes one unit of variance; therefore, the average contribution is 1/(# of variables of the table).\n\n\nR code\nres.plsr.plot$results.graphs$ctrW1.plot\n\n\n\n\n\n\n\n\n\nR code\nres.plsr.plot$results.graphs$ctrW2.plot\n\n\n\n\n\n\n\n\n\nR code\nres.plsr.plot$results.graphs$LoadingsMap.X\n\n\n\n\n\n\n\n\n\nR code\nres.plsr.plot$results.graphs$ctrC1.plot\n\n\n\n\n\n\n\n\n\nR code\nres.plsr.plot$results.graphs$ctrC2.plot\n\n\n\n\n\n\n\n\n\nR code\nres.plsr.plot$results.graphs$LoadingsMap.Y\n\n\n\n\n\n\n\n\n\nFrom these two bar plots, the first dimension is characterized by (1) the positive association between Alcohol and Tannin from the Chemical data and Woody and Astringent from the Sensory data, and (2) the negative association between these variables and Hedonic from the Sensory data.\nTogether with the latent variable plot, we found that, as compared to the rosé and the white wines in the sample, the red wines are less Hedonic and stronger in Alcohol, Tannin, Woody, and Astringent.\n\n\nCircles of correlations\nThe circle of correlations illustrate how the variables are correlated with each other and with the dimensions. From this figure, the length of an arrow indicates how much this variable is explained by the two given dimensions. The cosine between any two arrows gives their correlation. The cosine between a variable and an axis gives the correlation between that variable and the corresponding dimension.\nIn this figure, an angle closer to 0° indicates a correlation close to 1; an angle closer to 180° indicates a correlation close to -1; and an 90° angle indicates 0 correlation. However, it’s worth noted that this implication of correlation might only be true within the given dimensions. When a variable is far away from the circle, it is not fully explained by the dimensions, and other dimensions might be characterized by other pattern of relationship between this and other variables.\n\n\nR code\nres.plsr.plot$results.graphs$heatmap.rty\n\n\n\n\n\n\n\n\n\nR code\nres.plsr.plot$results.graphs$cirCorY.plot\n\n\n\n\n\n\n\n\n\nThese circles of correlations show that Alcohol, Tannin, Woody, Astringent, and Hedonic are strongly correlated to Dimension 1 with Henodic inversely correlated with all other variables. These variables are mostly explained by the first dimension and have close-to-zero correlation with the second dimension (which is not included and discussed in the previous sections)."
  },
  {
    "objectID": "pages/E_PLSR.html#inference-plots-and-results",
    "href": "pages/E_PLSR.html#inference-plots-and-results",
    "title": "PLSR on Wines",
    "section": "Inference plots and results",
    "text": "Inference plots and results\n\nThe prediction (random effect)\n\n\nR code\nres.plsr.plot$results.graphs$YYjack.plot\n\n\n\n\n\n\n\n\n\n\n\nThe predicted residuals estimated sum of squares (PRESS) of Y (random effect)\n\n\nR code\nres.plsr.plot$results.graphs$Y.PRESS.plot"
  },
  {
    "objectID": "pages/B_PCA.html",
    "href": "pages/B_PCA.html",
    "title": "PCA on Wines",
    "section": "",
    "text": "In this vignette we show how to perform a principal component analysis"
  },
  {
    "objectID": "pages/B_PCA.html#load-the-libraries",
    "href": "pages/B_PCA.html#load-the-libraries",
    "title": "PCA on Wines",
    "section": "Load the libraries",
    "text": "Load the libraries\nThe following code loads the libraries needed for the analysis:\n\n\nR code\nlibrary(dplyr)\nlibrary(ExPosition)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(ggplot2)\nlibrary(InPosition)\nlibrary(R4SPISE2022)\nset.seed(564)"
  },
  {
    "objectID": "pages/B_PCA.html#load-the-wine-data",
    "href": "pages/B_PCA.html#load-the-wine-data",
    "title": "PCA on Wines",
    "section": "Load the Wine data",
    "text": "Load the Wine data\nWith the following command\n\n\nR code\ndata(\"winesOf3Colors\", package = \"data4PCCAR\")\nwines &lt;- winesOf3Colors$winesDescriptors[,4:17]\n\n\n\n\nR code\nwineColors &lt;- list()\nwineColors$oc &lt;- as.matrix(as.character(recode(winesOf3Colors$winesDescriptors$color, red = 'indianred4', \n                white = 'gold', rose = 'lightpink2')))\nwineColors$gc &lt;- as.matrix(c(red = 'indianred4', \n                white = 'gold', rose = 'lightpink2'))\n\nvarColors &lt;- list()\nvarColors$oc[[1]] &lt;- as.matrix(rep(\"darkorange1\", 4))\nvarColors$oc[[2]] &lt;- as.matrix(rep(\"olivedrab3\", 8))"
  },
  {
    "objectID": "pages/B_PCA.html#run-the-principal-component-analysis-pca",
    "href": "pages/B_PCA.html#run-the-principal-component-analysis-pca",
    "title": "PCA on Wines",
    "section": "Run the Principal Component Analysis (PCA)",
    "text": "Run the Principal Component Analysis (PCA)\n\n\nR code\nres.pca &lt;- epPCA(wines, \n                 center = TRUE, # Center the data\n                 scale = TRUE, # Normalize the variables\n                 graphs = FALSE) \n\n\nBy default, this function will preprocess the variables in the data set (i.e., the columns of the data table) by 1) centering them (option center = TRUE after pre-processing all variables have mean equals to 0) and 2) scaling them (option scale = TRUE after pre-processing all variables have a sum of squares equals to , being the number of rows)."
  },
  {
    "objectID": "pages/B_PCA.html#plot-the-results",
    "href": "pages/B_PCA.html#plot-the-results",
    "title": "PCA on Wines",
    "section": "Plot the results",
    "text": "Plot the results\n\n\nR code\nres.plot.pca &lt;- OTAplot(\n    resPCA = res.pca,\n    data = wines, col4I = wineColors$oc,\n    )\n\n\n\nresults.stats: useful statistics after performing PCA, among which one can find the factor scores, loadings, eigenvalues, and contributions;\nresults.graphs: all the PCA graphs (heatmaps, screeplot, factor map, correlation circles, loading maps etc.)\ndescription.graphs: the titles of these graphs, used as titles in the PPTX file.\n\n\nCorrelations of the variables\nWe can check the data by plotting the correlation matrix between the variables. This correlation matrix is where the components are extracted.\n\n\nR code\nres.plot.pca$results.graphs$correlation\n\n\n\n\n\n\n\n\n\n\n\nScree plot\nThe scree plot shows the eigenvalues of each component. These eigenvalues give the variance of each component (or called dimension in the figure). In other words, the singular values, which are the square root of the eigenvalues, give the standard deviations of these components. The sum of the eigenvalues is equal to the total inertia of the data.\n\n\nR code\nres.plot.pca$results.graphs$scree\n\n\n\n\n\n\n\n\n\nAccording to the elbow test, there are four dimensions to keep for these data.\n\n\nFactor scores (rows)\nHere, the observation map shows how the observations (i.e., rows) are represented in the component space. If center = TRUE when running a PCA with epPCA, the origin is at the center (i.e., is the average / barycenter) of all observations. (If it’s not, something’s wrong)\n\n\nR code\nres.plot.pca$results.graphs$factorScoresI12\n\n\n\n\n\n\n\n\n\nThe wines are colored according to their type (i.e., red, white or rosé in this figures. The result in this plot showed that the first dimension separates all red wines from white and rosé, and the second dimension separates white from rosé.\n\n\nCircle of correlation\nThe circle of correlations illustrate how the variables are correlated with each other and with the dimensions. From this figure, the length of an arrow indicates how much this variable is explained by the two given dimensions. The cosine between any two arrows gives their correlation. The cosine between a variable and an axis gives the correlation between that variable and the corresponding dimension.\nIn this figure, an angle closer to 0° indicates a correlation close to 1; an angle closer to 180° indicates a correlation close to -1; and an 90° angle indicates 0 correlation. However, it’s worth noted that this implication of correlation might only be true within the given dimensions. When a variable is far away from the circle, it is not fully explained by the dimensions, and other dimensions might be characterized by other pattern of relationship between this and other variables.\n\n\nR code\nres.plot.pca$results.graphs$cosineCircleArrowJ12\n\n\n\n\n\n\n\n\n\nThis circle of correlation plot illustrates that Dimension 1 is Tannin, Astringent, Woody, and Alcohol (as well as Price and Spicy) versus Hedonic (as well as Sugar, Sweet, Floral, Acidic, Vegetal, and Acidity); Dimension 2 is Fruity, Spicy, Sugar and Sweet versus Acidity, Floral, Acidic, Price, and Vegetal. Interestingly, Price, as well as the anti-correlated Sweet and Sugar, are orthogonal to Spicy, Acidity, Acidic, Floral, and Vegetal, where Spicy is anti-correlated to the other variables."
  },
  {
    "objectID": "pages/B_PCA.html#inference-plots-and-results",
    "href": "pages/B_PCA.html#inference-plots-and-results",
    "title": "PCA on Wines",
    "section": "Inference plots and results",
    "text": "Inference plots and results\nThe inference analysis of PCA (performed by OTAplotInference) includes bootstrap test of the proportion of variance explained, permutation tests of the eigenvalues, the bootstrap tests of the column factor scores \\(\\mathbf{G}\\) (i.e., the right singular vectors scaled to have the variance of each dimension equals the corresponding singular value; \\(\\mathbf{G} = \\mathbf{Q}\\boldsymbol{\\Delta}\\) with \\(\\mathbf{X = P}\\boldsymbol{\\Delta}\\mathbf{Q}^\\top\\)). These column factor scores are stored as fj in the output of epPCA.\n\n\nR code\nres.plot.pca.inference &lt;- OTAplotInference(\n    resPCA = res.pca,\n    data = wines, col4I = wineColors$oc, \n    ) %&gt;% suppressMessages()\n\n\n\nBootstrap and permutation tests on the eigenvalues\nThe inference scree plot illustrates the 95% bootstrap confidence intervals of the percentage of variance explained by each eigenvalue. If an interval includes 0, the component explains reliably larger than 0% of the variance.\n\n\nR code\nres.plot.pca.inference$results.graphs$scree\n\n\n\n\n\n\n\n\n\nThe bootstrap test identifies one significant dimension explains the variance reliably larger than 0%. The permutation test identifies one significant dimension with an eigenvalue significantly larger than 0.\n\n\nBootstrap test on the column factor scores\nThe bar plot illustrates the bootstrap ratios which equals \\[\\frac{M_{g_{j}boot}}{SD_{g_{j}boot}},\\] where \\(M_{g_{j}boot}\\) is the mean of the bootstrapped sample of the jth column factor score and \\(SD_{g_{j}boot}\\) is the bootstrapped standard deviation of the factor score. A bootstrap ratio is equivalent to a t-statistics for the column factor score with the \\(\\mathrm{H}_0: g_j = 0\\). The threshold is set to 2 to approximate the critical t-value of 1.96 at \\(\\alpha\\) = .05.\n\n\nR code\nres.plot.pca.inference$results.graphs$BR1\n\n\n\n\n\n\n\n\n\n\n\nR code\nres.plot.pca.inference$results.graphs$BR2\n\n\n\n\n\n\n\n\n\nThe results show that Astringent is the only significant contributor to Dimension 1, and there is no significant factor scores for Dimension 1 that is reliably different from 0."
  }
]